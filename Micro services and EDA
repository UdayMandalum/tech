Microservices vs Monolothis 
Advantage is when handeling 
complexity : Breakdown of program helps developemnt with diferrent teams , deplyments 
scalability : Isloate workloads to undertand the scaling needs based on the capacity needs
Microservices should be loosely coupled 
Consider Network latency, communication failure (availability)

Key Advantages of Microservices
Independent Deployment	Each service can be deployed on its own without redeploying the whole system. This reduces deployment risk and increases agility.
Technology Flexibility	Each microservice can use the most appropriate technology stack (language, database, framework) rather than forcing one stack across the entire system.
Scalability	You can scale only the services that need more resources instead of scaling the whole application. Leads to better use of infrastructure and reduced cost.
Better Fault Isolation	If one microservice fails, it doesn’t bring down the entire system. Other services continue to work.
Smaller, Focused Codebases	Services are smaller and focused on a single business capability → easier to understand, develop, test, and maintain.
Faster Time to Market	Small, independent teams can work in parallel on different services without blocking each other. New features can be delivered faster.
Organizational Alignment	Teams align around business areas (e.g., Payments Service, Order Service), improving ownership and domain understanding.
Easier Continuous Delivery	Because services are loosely coupled and independently deployable, automated CI/CD pipelines become easier to implement.
Reusability	Services can be reused across multiple products / channels (ex: the same User Profile Service can be used by the web app and mobile app).
Supports Event-Driven Design	Microservices naturally encourage asynchronous communication patterns, enabling true event-driven architecture with message brokers or Kafka.

Remote Procedure call (RPC) : eg. Rest endpoint . Good when dependency relationship is simple and stable . Example Workbench UI=> Business Layer => SQL cache service, OLAP service=> 
Message-driven : Messages published in a fire and forget manner via Message broker. Eliminates effects of Latency & Availability. Incorporates queing mechanism. 
              Ex. Bond Index Restatement : Impact analysis service (Queued) 

Kafka is a distributed event streaming platform that acts like a high-performance, fault-tolerant message broker.
It’s used to publish, store, and consume messages (called events) in real time or near real time.

Apache Kafka is an open-source, distributed event streaming platform engineered for high performance, scalability, and durability.
It uses producers to send messages to topics, and consumers to read them, with messages being stored in ordered, immutable partitions across multiple brokers (servers).
It is highly suited for real-time data processing and asynchronous message queuing in system design.

Step 1 – Producers send messages to Kafka
Producers are your data sources or services that create messages.
They send these messages to Kafka topics (like named channels).

Step 2 – Kafka stores the messages
Messages are written to partitions inside the topic.
Kafka persists messages to disk, replicates them for fault tolerance, and keeps them for a configured retention period (even after consumers read them).
This means multiple consumers can read the same message independently at different times.

Step 3 – Consumers process messages
Consumers subscribe to topics.
They pull messages from Kafka and process them asynchronously.

Step 4 – Decoupling & Scalability
Producers don’t need to know who is consuming their messages.
You can add more consumers to scale processing — Kafka will balance partitions across them.
Services can be updated, redeployed, or even offline temporarily without breaking the flow (Kafka buffers messages until they’re processed).

Versioning of service makes it possible to change a service without breaking other services that depends on it. Other services can use the deprecated version till they 
change the code to use the new version. 

Consumer Retries:  own retry logic. One common pattern is to set up a custom topic that we can move failed messages to and then have a separate consumer that processes
these messages. This way, we can retry messages as many times as we want without affecting the main consumer. 
If a given message is retried too many times, we can move it to a dead letter queue (DLQ). DLQs are just a place to store failed messages so that we can investigate them later.


